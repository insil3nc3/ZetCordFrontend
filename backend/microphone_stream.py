import sounddevice as sd
from aiortc import MediaStreamTrack
import time
import fractions
import numpy as np
import asyncio
import logging
import threading
from av import AudioFrame

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class AudioStreamTrack(MediaStreamTrack):
    """–¢—Ä–µ–∫ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
    kind = "audio"

    def __init__(self, sample_rate=48000, channels=1, frame_size=960):
        super().__init__()
        self.sample_rate = sample_rate
        self.channels = channels
        self.frame_size = frame_size  # –†–∞–∑–º–µ—Ä —Ñ—Ä–µ–π–º–∞ –≤ —Å—ç–º–ø–ª–∞—Ö

        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        self._start = time.time()
        self._pts = 0
        self._time_base = fractions.Fraction(1, sample_rate)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        self.stream = None
        self._init_microphone()

        # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö (–∏—Å–ø–æ–ª—å–∑—É–µ–º threading.Lock –≤–º–µ—Å—Ç–æ asyncio.Lock)
        self._buffer = np.array([], dtype=np.float32)
        self._buffer_lock = threading.Lock()

    def _init_microphone(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
            devices = sd.query_devices()
            logging.info("üéôÔ∏è –î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:")
            for i, dev in enumerate(devices):
                if dev['max_input_channels'] > 0:
                    logging.info(f"  {i}: {dev['name']} (–≤—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {dev['max_input_channels']})")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            device = sd.default.device[0]  # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–≤–æ–¥–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

            if device is None:
                raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–≤–æ–¥–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")

            device_info = devices[device]
            if device_info['max_input_channels'] < 1:
                raise RuntimeError(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {device_info['name']} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω–æ–π –∑–≤—É–∫")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É —Ñ–æ—Ä–º–∞—Ç–∞
            sd.check_input_settings(
                device=device,
                samplerate=self.sample_rate,
                channels=self.channels,
                dtype='float32'
            )

            # –°–æ–∑–¥–∞–µ–º –ø–æ—Ç–æ–∫
            self.stream = sd.InputStream(
                samplerate=self.sample_rate,
                channels=self.channels,
                blocksize=self.frame_size,
                callback=self._audio_callback,
                device=device,
                dtype='float32'
            )

            self.stream.start()
            logging.info(f"üéôÔ∏è –ú–∏–∫—Ä–æ—Ñ–æ–Ω –∑–∞–ø—É—â–µ–Ω: {device_info['name']} ({self.sample_rate}Hz, {self.channels} –∫–∞–Ω–∞–ª–æ–≤)")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}")
            self.stream = None
            raise

    def _audio_callback(self, indata, frames, time_info, status):
        """Callback –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
        if status:
            logging.warning(f"‚ö†Ô∏è –°—Ç–∞—Ç—É—Å –∞—É–¥–∏–æ: {status}")

        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤
            audio_data = indata.flatten().copy()

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (–∏—Å–ø–æ–ª—å–∑—É–µ–º threading.Lock)
            self._add_to_buffer_sync(audio_data)

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ audio_callback: {e}")

    def _add_to_buffer_sync(self, audio_data):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –±—É—Ñ–µ—Ä"""
        with self._buffer_lock:
            self._buffer = np.concatenate([self._buffer, audio_data])

    async def recv(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∞—É–¥–∏–æ—Ñ—Ä–µ–π–º–∞"""
        try:
            # –ñ–¥–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
            while True:
                with self._buffer_lock:
                    if len(self._buffer) >= self.frame_size:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ—Ä–µ–π–º –∏–∑ –±—É—Ñ–µ—Ä–∞
                        frame_data = self._buffer[:self.frame_size].copy()
                        self._buffer = self._buffer[self.frame_size:]
                        break

                await asyncio.sleep(0.001)  # –ú–∞–ª–µ–Ω—å–∫–∞—è –ø–∞—É–∑–∞

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å—Ç–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
            frame_data = self._apply_noise_gate(frame_data)

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
            frame_data = self._normalize_audio(frame_data)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ int16 –¥–ª—è WebRTC
            frame_data_int16 = (frame_data * 32767).astype(np.int16)

            # –°–æ–∑–¥–∞–µ–º AudioFrame
            frame = AudioFrame(format="s16", layout="mono", samples=self.frame_size)
            frame.planes[0].update(frame_data_int16.tobytes())
            frame.sample_rate = self.sample_rate

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            frame.pts = self._pts
            frame.time_base = self._time_base
            self._pts += self.frame_size

            return frame

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ recv(): {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∏—à–∏–Ω—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self._create_silence_frame()

    def _apply_noise_gate(self, audio_data, threshold=0.01):
        """–ü—Ä–æ—Å—Ç–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ"""
        rms = np.sqrt(np.mean(audio_data ** 2))
        if rms < threshold:
            return audio_data * 0.1  # –°–∏–ª—å–Ω–æ –ø—Ä–∏–≥–ª—É—à–∞–µ–º —Ç–∏—Ö–∏–µ –∑–≤—É–∫–∏
        return audio_data

    def _normalize_audio(self, audio_data, target_level=0.3):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏"""
        max_amplitude = np.max(np.abs(audio_data))
        if max_amplitude > 0:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–æ —Ü–µ–ª–µ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è
            audio_data = audio_data * (target_level / max_amplitude)
        return np.clip(audio_data, -1.0, 1.0)

    def _create_silence_frame(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ—Ä–µ–π–º–∞ —Ç–∏—à–∏–Ω—ã"""
        silence_data = np.zeros(self.frame_size, dtype=np.int16)

        frame = AudioFrame(format="s16", layout="mono", samples=self.frame_size)
        frame.planes[0].update(silence_data.tobytes())
        frame.sample_rate = self.sample_rate

        frame.pts = self._pts
        frame.time_base = self._time_base
        self._pts += self.frame_size

        return frame

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
        if self.stream:
            try:
                if self.stream.active:
                    self.stream.stop()
                self.stream.close()
                print("üõë –ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}")
            finally:
                self.stream = None