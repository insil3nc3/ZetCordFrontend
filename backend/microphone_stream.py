import asyncio
from fractions import Fraction
import numpy as np
import sounddevice as sd
from aiortc import MediaStreamTrack
from av import AudioFrame

class MicrophoneStreamTrack(MediaStreamTrack):
    kind = "audio"

    def __init__(self, device=0, sample_rate=48000, chunk=960):
        super().__init__()
        self.sample_rate = sample_rate
        self.chunk = chunk
        self.buffer = asyncio.Queue()
        self._timestamp = 0
        self._running = True

        devices = sd.query_devices()
        print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:")
        for i, dev in enumerate(devices):
            print(f"{i}: {dev['name']} (in:{dev['max_input_channels']} out:{dev['max_output_channels']})")

        if device is None or device >= len(devices):
            print("‚ö† –£–∫–∞–∑–∞–Ω–æ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–∏–Ω–¥–µ–∫—Å 0)")
            device = 0

        input_channels = devices[device]['max_input_channels']
        if input_channels < 1:
            raise RuntimeError(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {devices[device]['name']} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω–æ–π –∑–≤—É–∫")

        self.channels = min(2, input_channels)  # –≤—ã–±–∏—Ä–∞–µ–º –º–∞–∫—Å–∏–º—É–º 2 –∫–∞–Ω–∞–ª–∞
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {devices[device]['name']} (–∏–Ω–¥–µ–∫—Å {device}), channels={self.channels}")

        try:
            self.stream = sd.InputStream(
                device=device,
                samplerate=self.sample_rate,
                channels=self.channels,
                blocksize=self.chunk,
                dtype='float32',
                callback=self._callback,
            )
            self.stream.start()
            print("‚úÖ –ú–∏–∫—Ä–æ—Ñ–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –∑–∞–ø—É—â–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞: {e}")
            raise

    def _callback(self, indata, frames, time_info, status):
        if not self._running:
            return
        if status:
            print(f"‚ö† Audio input status: {status}")
        self.buffer.put_nowait(indata.copy())

    async def recv(self):
        if not self._running:
            raise RuntimeError("–ú–∏–∫—Ä–æ—Ñ–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        data = await self.buffer.get()

        frame = AudioFrame.from_ndarray(
            data.T if data.ndim > 1 else data.reshape(-1, 1),
            format='flt',
            layout='mono' if self.channels == 1 else 'stereo'
        )
        frame.pts = self._timestamp
        frame.sample_rate = self.sample_rate
        frame.time_base = Fraction(1, self.sample_rate)
        self._timestamp += frame.samples
        return frame

    def stop(self):
        self._running = False
        if hasattr(self, 'stream') and self.stream:
            self.stream.stop()
            self.stream.close()
            print("üõë –ú–∏–∫—Ä–æ—Ñ–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
