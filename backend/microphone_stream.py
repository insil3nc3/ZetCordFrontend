import asyncio
import traceback
from fractions import Fraction
import numpy as np
import sounddevice as sd
from aiortc import MediaStreamTrack
from av import AudioFrame

class MicrophoneStreamTrack(MediaStreamTrack):
    kind = "audio"

    def __init__(self, device=0, sample_rate=48000, chunk=960, channels=None):
        super().__init__()
        self.sample_rate = sample_rate
        self.chunk = chunk
        self.buffer = asyncio.Queue()
        self._timestamp = 0
        self._running = True

        devices = sd.query_devices()
        print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:")
        for i, dev in enumerate(devices):
            print(f"{i}: {dev['name']} (in:{dev['max_input_channels']} out:{dev['max_output_channels']})")

        if device is None or device >= len(devices):
            print("‚ö† –£–∫–∞–∑–∞–Ω–æ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            device = sd.default.device[0]  # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–≤–æ–¥–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        device_info = devices[device]
        input_channels = device_info['max_input_channels']
        if input_channels < 1:
            raise RuntimeError(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {device_info['name']} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω–æ–π –∑–≤—É–∫")

        self.channels = channels if channels else min(2, input_channels)
        print(
            f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_info['name']} (–∏–Ω–¥–µ–∫—Å {device}), channels={self.channels}, default_samplerate={device_info['default_samplerate']}")

        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            sd.check_input_settings(
                device=device,
                samplerate=self.sample_rate,
                channels=self.channels,
                dtype='float32'
            )
            self.stream = sd.InputStream(
                device=device,
                samplerate=self.sample_rate,
                channels=self.channels,
                blocksize=self.chunk,
                dtype='float32',
                callback=self._callback,
            )
            self.stream.start()
            print("‚úÖ –ú–∏–∫—Ä–æ—Ñ–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –∑–∞–ø—É—â–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞: {type(e).__name__}: {e}")
            raise

    def _callback(self, indata, frames, time, status):
        if status:
            print(f"üé§ callback: status={status}")
        print(
            f"üé§ callback: indata.shape={indata.shape}, frames={frames}, status={status}, C_CONTIGUOUS={indata.flags['C_CONTIGUOUS']}")
        if self._running:
            self.buffer.put_nowait(indata.copy())

    async def recv(self):
        try:
            if not self._running:
                raise RuntimeError("–ú–∏–∫—Ä–æ—Ñ–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            data = await self.buffer.get()
            print(
                f"üéôÔ∏è recv(): –ø—Ä–∏—à–ª–∏ –¥–∞–Ω–Ω—ã–µ –æ—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞, shape={data.shape}, running={self._running}, C_CONTIGUOUS={data.flags['C_CONTIGUOUS']}")
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–µ—Ä–µ–æ –≤ –º–æ–Ω–æ
            if data.ndim > 1 and data.shape[1] == 2:
                data = np.mean(data, axis=1)
            elif data.ndim > 1:
                data = data[:, 0]
            # –£—Å–∏–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ (x10, —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –∫–ª–∏–ø–ø–∏–Ω–≥–∞)
            data = np.clip(data * 10.0, -1.0, 1.0)
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º float32 –≤ int16
            data = np.clip(data * 32768, -32768, 32767).astype(np.int16)
            data = np.ascontiguousarray(data.reshape(1, -1), dtype=np.int16)
            print(
                f"üéôÔ∏è –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: shape={data.shape}, C_CONTIGUOUS={data.flags['C_CONTIGUOUS']}, dtype={data.dtype}")

            try:
                frame = AudioFrame.from_ndarray(
                    data,
                    format='s16',
                    layout='mono'
                )
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ AudioFrame: {type(e).__name__}: {e}")
                raise

            frame.pts = self._timestamp
            frame.sample_rate = self.sample_rate
            frame.time_base = Fraction(1, self.sample_rate)
            self._timestamp += frame.samples
            print(
                f"üéôÔ∏è –í–æ–∑–≤—Ä–∞—â–µ–Ω —Ñ—Ä–µ–π–º: samples={frame.samples}, layout={frame.layout}, sample_rate={frame.sample_rate}, format={frame.format.name}")
            return frame
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ MicrophoneStreamTrack.recv: {type(e).__name__}: {e}")
            frame = AudioFrame.from_ndarray(
                np.ascontiguousarray(np.zeros((1, self.sample_rate // 100), dtype=np.int16)),
                format='s16',
                layout='mono'
            )
            frame.pts = self._timestamp
            frame.sample_rate = self.sample_rate
            frame.time_base = Fraction(1, self.sample_rate)
            self._timestamp += frame.samples
            return frame

    def stop(self):
        print("üõë –í—ã–∑–æ–≤ stop() –∏–∑:", traceback.format_stack())
        self._running = False
        if hasattr(self, 'stream') and self.stream:
            self.stream.stop()
            self.stream.close()
            print("üõë –ú–∏–∫—Ä–æ—Ñ–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")