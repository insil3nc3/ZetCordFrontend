import asyncio
import traceback
from fractions import Fraction
import numpy as np
import sounddevice as sd
from aiortc import MediaStreamTrack
from av import AudioFrame
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class MicrophoneStreamTrack(MediaStreamTrack):
    kind = "audio"

    def __init__(self, device=None, sample_rate=44100, chunk=960, channels=None):
        super().__init__()
        self.sample_rate = sample_rate
        self.chunk = chunk
        self.buffer = asyncio.Queue()
        self._timestamp = 0
        self._running = True

        devices = sd.query_devices()
        logging.info("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:")
        for i, dev in enumerate(devices):
            logging.info(f"{i}: {dev['name']} (in:{dev['max_input_channels']} out:{dev['max_output_channels']})")

        device = device if device is not None else sd.default.device[0]
        if device is None or device >= len(devices):
            logging.warning("‚ö† –£–∫–∞–∑–∞–Ω–æ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            device = sd.default.device[0]

        device_info = devices[device]
        input_channels = device_info['max_input_channels']
        if input_channels < 1:
            raise RuntimeError(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {device_info['name']} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω–æ–π –∑–≤—É–∫")

        self.channels = channels if channels else min(2, input_channels)
        logging.info(
            f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_info['name']} (–∏–Ω–¥–µ–∫—Å {device}), channels={self.channels}, default_samplerate={device_info['default_samplerate']}")

        try:
            sd.check_input_settings(
                device=device,
                samplerate=self.sample_rate,
                channels=self.channels,
                dtype='float32'
            )
            self.stream = sd.InputStream(
                device=device,
                samplerate=self.sample_rate,
                channels=self.channels,
                blocksize=self.chunk,
                dtype='float32',
                callback=self._callback,
            )
            self.stream.start()
            logging.info("‚úÖ –ú–∏–∫—Ä–æ—Ñ–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –∑–∞–ø—É—â–µ–Ω")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞: {type(e).__name__}: {e}")
            raise

    def _callback(self, indata, frames, time, status):
        if status:
            logging.warning(f"üé§ callback: status={status}")
        logging.debug(
            f"üé§ callback: indata.shape={indata.shape}, frames={frames}, max={np.max(np.abs(indata))}, status={status}, C_CONTIGUOUS={indata.flags['C_CONTIGUOUS']}")
        if self._running:
            self.buffer.put_nowait(indata.copy())

    async def recv(self):
        try:
            if not self._running or not self.stream.active:
                raise RuntimeError("–ú–∏–∫—Ä–æ—Ñ–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω")

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±—É—Ñ–µ—Ä–∞
            data = await self.buffer.get()

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            logging.debug(f"Raw audio data type: {type(data)}, shape: {getattr(data, 'shape', 'no shape')}")

            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —è–≤–ª—è—é—Ç—Å—è numpy –º–∞—Å—Å–∏–≤–æ–º
            if not isinstance(data, np.ndarray):
                data = np.frombuffer(data.tobytes() if hasattr(data, 'tobytes') else bytes(data),
                                     dtype=np.float32)
                data = data.reshape(-1, 1)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 2D –º–∞—Å—Å–∏–≤

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–≥–æ–∫–∞–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ
            if data.ndim > 1 and data.shape[1] == 2:
                data = np.mean(data, axis=1)  # –ú–∏–∫—à–∏—Ä—É–µ–º —Å—Ç–µ—Ä–µ–æ –≤ –º–æ–Ω–æ
            elif data.ndim > 1:
                data = data[:, 0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —É—Å–∏–ª–µ–Ω–∏–µ
            data = np.clip(data * 20.0, -1.0, 1.0)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ 16-–±–∏—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            data = np.clip(data * 32768, -32768, 32767).astype(np.int16)
            data = np.ascontiguousarray(data.reshape(1, -1))

            # –°–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ—Ñ—Ä–µ–π–º —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            frame = AudioFrame.from_ndarray(
                data,
                format='s16',
                layout='mono'
            )

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            frame.pts = self._timestamp
            frame.sample_rate = self.sample_rate
            frame.time_base = Fraction(1, self.sample_rate)
            self._timestamp += frame.samples

            return frame

        except Exception as e:
            logging.error(f"Error in MicrophoneStreamTrack.recv: {e}", exc_info=True)
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∏—Ö–∏–π —Ñ—Ä–µ–π–º –ø—Ä–∏ –æ—à–∏–±–∫–µ
            silent_data = np.zeros((1, self.sample_rate // 100), dtype=np.int16)
            frame = AudioFrame.from_ndarray(
                silent_data,
                format='s16',
                layout='mono'
            )
            frame.pts = self._timestamp
            frame.sample_rate = self.sample_rate
            frame.time_base = Fraction(1, self.sample_rate)
            self._timestamp += silent_data.shape[1]
            return frame

    def stop(self):
        logging.info("üõë –í—ã–∑–æ–≤ stop() –∏–∑: %s", ''.join(traceback.format_stack()[:-1]))
        self._running = False
        if hasattr(self, 'stream') and self.stream:
            if self.stream.active:
                self.stream.stop()
            self.stream.close()
            logging.info("üõë –ú–∏–∫—Ä–æ—Ñ–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")